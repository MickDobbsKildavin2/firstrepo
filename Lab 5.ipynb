{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5b1f637",
   "metadata": {},
   "source": [
    "# Lab 5 for Big Data programming.\n",
    "# Apache Spark Machine Learning using Dataframes in Google Colab\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7739c1ee",
   "metadata": {},
   "source": [
    "# 1.\tSetup an Apache Spark instance in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f2c8c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run once.\n",
    "\n",
    "!apt-get install openjdk-8-jdk-headless -qq > /dev/null\n",
    "!wget -q https://archive.apache.org/dist/spark/spark-3.0.2/spark-3.0.2-bin-hadoop2.7.tgz\n",
    "!tar xf spark-3.0.2-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark\n",
    "\n",
    "#Run Once\n",
    "import os\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.0.2-bin-hadoop2.7\"\n",
    "import findspark\n",
    "findspark.init()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b10f08d4",
   "metadata": {},
   "source": [
    "# 2.\tCreate a Spark session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "386acf61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder\\\n",
    "        .master(\"local\")\\\n",
    "        .appName(\"Colab\")\\\n",
    "        .config('spark.ui.port', '4050')\\\n",
    "        .getOrCreate()\n",
    "spark\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad50a00a",
   "metadata": {},
   "source": [
    "# 3.\tDownload the Iris dataset and another dataset of your choosing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8a6ed8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\" -O sample_data/iris.data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a215916e",
   "metadata": {},
   "source": [
    "# 4.\tImport the Iris dataset into a dataframe and insert screenshot of df.show()command output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "51f4e094",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a047b023670f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#df = spark.read.csv('sample_data/iris.data', header=False, sep=\",\", inferSchema=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'sample_data/iris.data'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minferSchema\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtoDF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"SepalLength\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"SepalWidth\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"PetalLength\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"PetalWidth\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"Class\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "#df = spark.read.csv('sample_data/iris.data', header=False, sep=\",\", inferSchema=True)\n",
    "df = spark.read.csv('sample_data/iris.data', inferSchema=True)\\\n",
    ".toDF(\"SepalLength\",\"SepalWidth\",\"PetalLength\",\"PetalWidth\",\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bee4106",
   "metadata": {},
   "source": [
    "# 5.\tSpark ML can only deal with one features column - so we need to vectorise the multiple columns into one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56081b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.linalg import Vectors\n",
    "from pyspark.ml.feature import VectorAssembler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cf0ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_assembler=VectorAssembler(\\\n",
    "inputCols=[\"SepalLength\",\"SepalWidth\",\"PetalLength\",\"PetalWidth\"],\\\n",
    "outputCol=\"features\")\n",
    "df_temp=vector_assembler.transform(df)\n",
    "df_temp.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a0e244",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_temp=df_temp.drop(\"SepalLength\",\"SepalWidth\",\"PetalLength\",\"PetalWidth\")\n",
    "df_temp.show(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31a56a38",
   "metadata": {},
   "source": [
    "# 6.\tThe final data preparation step is to index the Class column - to use numeric rather than text values - run the following command and display your output of Class, features & ClassIndex columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da2a1ef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import StringIndexer\n",
    "l_indexer=StringIndexer(inputCol=\"Class\", outputCol=\"ClassIndex\")\n",
    "df = l_indexer.fit(df).transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25c31775",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07307297",
   "metadata": {},
   "source": [
    "# 7.\tSplit your data into training and test datasets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcd5495",
   "metadata": {},
   "outputs": [],
   "source": [
    "(trainingData,testData) = df.randomSplit([0.7,0.3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba3ce0",
   "metadata": {},
   "source": [
    "# 8.\tDecision Tree Classifier \n",
    "## Specify the DecisionTreeClassifier and train the model on your training dataset:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51aa78dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import DecisionTreeClassifier \n",
    "from pyspark.ml.evaluation importMulticlassClassificationEvaluator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ea2a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(labelCol=\"ClassIndex\",featuresCol=\"features\")\n",
    "model=dt.fit(trainingData)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4692ce",
   "metadata": {},
   "source": [
    "# 9.\tTest your model with your test dataset: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1487d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.transform(testData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94b91670",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.select(\"prediction\",\"ClassIndex\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43df52f9",
   "metadata": {},
   "source": [
    "# 10.\tRun an evaluator function to show the accuracy of your model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61f6143",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator= MulticlassClassificationEvaluator(\\\n",
    "labelCol=\"ClassIndex\", predictionCol=\"prediction\",\\\n",
    "metricName=\"accuracy\")\n",
    "accuracy=evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print(\"Test Set accuracy = \" +str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b157244e",
   "metadata": {},
   "source": [
    "# 11.\tRandom Forest Classifier\n",
    "\n",
    "## Specify the RandomForestClassifier, train the model on your training dataset, predict using your test dataset, and run an evaluator to test accuracy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3578121",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import RandomForestClassifier \n",
    "rf=RandomForestClassifier(labelCol=\"ClassIndex\",\\\n",
    "featuresCol=\"features\",numTrees=10)\n",
    "model=rf.fit(trainingData)\n",
    "predictions=model.transform(testData)\n",
    "predictions.select(\"prediction\",\"ClassIndex\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "443d95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator= \\\n",
    "MulticlassClassificationEvaluator(labelCol=\"ClassIndex\",\\\n",
    "predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "accuracy=evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print(\"Test Set accuracy = \" +str(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bbecf19",
   "metadata": {},
   "source": [
    "# 12.\tNaive Bayes Classifier\n",
    "## Specify the NaiveBayes classifier, train the model on your training dataset, predict using your test dataset, and run an evaluator to test accuracy:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c51651",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.classification import NaiveBayes \n",
    "nb=NaiveBayes(labelCol=\"ClassIndex\",\\\n",
    "featuresCol=\"features\",smoothing=1.0,\\\n",
    "modelType=\"multinomial\")\n",
    "model=nb.fit(train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be780693",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=model.transform(test)\n",
    "predictions.select(\"Class\",\"ClassIndex\",\n",
    "\"probability\",\"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0965acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator= \\\n",
    "MulticlassClassificationEvaluator(labelCol=\"ClassIndex\",\\\n",
    "predictionCol=\"prediction\",metricName=\"accuracy\")\n",
    "accuracy=evaluator.evaluate(predictions)\n",
    "print(\"Test Error = %g\" % (1.0 - accuracy))\n",
    "print(\"Test Set accuracy = \" +str(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da328635",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
